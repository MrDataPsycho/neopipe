{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#neopipe","title":"NeoPipe","text":"<p>A Python library for seamless function orchestration, inspired by Rust and scikit-learn pipelines. Designed to streamline workflow management in microservices and AI-powered applications.</p>"},{"location":"#key-features","title":"Key Features:","text":"<ul> <li>Pythonic implementation</li> <li>Efficient function pipelining</li> <li>Inspired by Rust's approach to data flow</li> <li>Tailored for microservices architecture</li> <li>Simplify orchestration of small API driven function (OpenAI, Claudi, other 3rd party API)</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>$ pip install neopipe\n</code></pre>"},{"location":"#license","title":"License","text":"<p><code>neopipe</code> was created by MrDataPsycho. It is licensed under the terms of the MIT license.</p>"},{"location":"api/async_pipeline/","title":"Async Pipeline","text":""},{"location":"api/async_pipeline/#neopipe.async_pipeline.AsyncPipeline","title":"<code>AsyncPipeline</code>","text":"<p>               Bases: <code>Generic[T, E]</code></p> <p>An asynchronous pipeline supporting three modes:</p> <ol> <li>run: Concurrent execution of registered tasks, one-to-one with inputs.</li> <li>run_sequence: Sequential chaining of tasks.</li> <li>run_parallel: Concurrent execution of multiple pipelines, returning PipelineResult objects.</li> </ol> <p>Each method supports an optional debug flag to capture per-task traces.</p> <p>Tasks must consume and return a Result[T, E].</p> Source code in <code>neopipe/async_pipeline.py</code> <pre><code>class AsyncPipeline(Generic[T, E]):\n    \"\"\"\n    An asynchronous pipeline supporting three modes:\n\n    1. run: Concurrent execution of registered tasks, one-to-one with inputs.\n    2. run_sequence: Sequential chaining of tasks.\n    3. run_parallel: Concurrent execution of multiple pipelines, returning PipelineResult objects.\n\n    Each method supports an optional debug flag to capture per-task traces.\n\n    Tasks must consume and return a Result[T, E].\n    \"\"\"\n\n    def __init__(self, name: Optional[str] = None):\n        self.tasks: List[BaseAsyncTask[T, E]] = []\n        self.pipeline_id = uuid.uuid4()\n        self.name = name or f\"AsyncPipeline-{self.pipeline_id}\"\n\n    @classmethod\n    def from_tasks(\n        cls, tasks: List[BaseAsyncTask[T, E]], name: Optional[str] = None\n    ) -&gt; \"AsyncPipeline[T, E]\":\n        pipeline = cls(name)\n        for task in tasks:\n            pipeline.add_task(task)\n        return pipeline\n\n    def add_task(self, task: BaseAsyncTask[T, E]) -&gt; None:\n        self._validate_task(task)\n        self.tasks.append(task)\n\n    def _validate_task(self, task: BaseAsyncTask[T, E]) -&gt; None:\n        if not isinstance(task, BaseAsyncTask):\n            raise TypeError(f\"Only BaseAsyncTask instances allowed, got {type(task)}\")\n        sig = inspect.signature(task.execute)\n        params = [p for p in sig.parameters.values() if p.name != \"self\"]\n        if len(params) != 1:\n            raise TypeError(\n                f\"Task '{task.task_name}' must have exactly one input parameter\"\n            )\n        origin = getattr(params[0].annotation, \"__origin__\", None)\n        if origin is not Result:\n            raise TypeError(\n                f\"Task '{task.task_name}' first arg must be Result[T, E], got {params[0].annotation}\"\n            )\n\n    async def run(\n        self, inputs: List[Result[T, E]], debug: bool = False\n    ) -&gt; Result[\n        Union[List[U], Tuple[Optional[List[U]], List[Tuple[str, Result[T, E]]]]], E\n    ]:\n        \"\"\"\n        Concurrently execute registered tasks with matching inputs.\n\n        Returns a list of outputs or a debug trace.\n        \"\"\"\n        if len(inputs) != len(self.tasks):\n            return Err(\"Number of inputs must match number of tasks\")\n\n        coros = [task(inp) for task, inp in zip(self.tasks, inputs)]\n        try:\n            results: List[Result[U, E]] = await asyncio.gather(*coros)\n        except Exception as e:\n            logger.exception(f\"[{self.name}] run() exception\")\n            return Err(str(e))\n\n        trace: List[Tuple[str, Result[T, E]]] = []\n        outputs: List[U] = []\n        for task, res in zip(self.tasks, results):\n            if debug:\n                trace.append((task.task_name, res))\n            if res.is_err():\n                if debug:\n                    return Ok((None, trace))\n                return res\n            outputs.append(res.unwrap())\n        return Ok((outputs, trace)) if debug else Ok(outputs)\n\n    async def run_sequence(\n        self, input_result: Result[T, E], debug: bool = False\n    ) -&gt; Result[Union[U, Tuple[Optional[U], List[Tuple[str, Result[T, E]]]]], E]:\n        \"\"\"\n        Execute registered tasks in sequence.\n        \"\"\"\n        trace: List[Tuple[str, Result[Any, E]]] = []\n        current: Result[Any, E] = input_result\n        for task in self.tasks:\n            try:\n                res: Result[U, E] = await task(current)\n            except Exception as e:\n                logger.exception(\n                    f\"[{self.name}] run_sequence exception in {task.task_name}\"\n                )\n                return Err(str(e))\n            trace.append((task.task_name, res))\n            if res.is_err():\n                if debug:\n                    return Ok((None, trace))\n                return res\n            current = res  # type: ignore\n        final = current.unwrap()  # type: ignore\n        return Ok((final, trace)) if debug else Ok(final)\n\n    @staticmethod\n    async def run_parallel(\n        pipelines: List[\"AsyncPipeline[T, E]\"],\n        inputs: List[Result[T, E]],\n        debug: bool = False,\n    ) -&gt; Result[\n        Union[\n            List[PipelineResult], Tuple[Optional[List[PipelineResult]], PipelineTrace]\n        ],\n        E,\n    ]:\n        \"\"\"\n        Execute multiple pipelines concurrently, each with its own input.\n\n        Returns:\n            - debug=False: Ok([PipelineResult, ...]) or Err(first_error)\n            - debug=True : Ok((List[PipelineResult], PipelineTrace))\n        \"\"\"\n        if len(pipelines) != len(inputs):\n            raise AssertionError(\"Each pipeline must have a corresponding input Result\")\n\n        coros = [p.run_sequence(inp, debug) for p, inp in zip(pipelines, inputs)]\n        try:\n            results = await asyncio.gather(*coros)\n        except Exception as e:\n            logger.exception(\"run_parallel exception\")\n            return Err(str(e))\n\n        pipeline_results: List[PipelineResult] = []\n        all_traces: List[SinglePipelineTrace[E]] = []\n\n        for pipeline, res in zip(pipelines, results):\n            if res.is_err():\n                return res\n            if debug:\n                val, trace = res.unwrap()\n                pipeline_results.append(PipelineResult(name=pipeline.name, result=val))\n                all_traces.append(SinglePipelineTrace(name=pipeline.name, tasks=trace))\n            else:\n                pipeline_results.append(\n                    PipelineResult(name=pipeline.name, result=res.unwrap())\n                )\n\n        if debug:\n            return Ok((pipeline_results, PipelineTrace(pipelines=all_traces)))\n        return Ok(pipeline_results)\n\n    def __str__(self) -&gt; str:\n        names = \", \".join(t.task_name for t in self.tasks)\n        return f\"{self.name}([{names}])\"\n\n    def __repr__(self) -&gt; str:\n        return self.__str__()\n</code></pre>"},{"location":"api/async_pipeline/#neopipe.async_pipeline.AsyncPipeline.run","title":"<code>run(inputs, debug=False)</code>  <code>async</code>","text":"<p>Concurrently execute registered tasks with matching inputs.</p> <p>Returns a list of outputs or a debug trace.</p> Source code in <code>neopipe/async_pipeline.py</code> <pre><code>async def run(\n    self, inputs: List[Result[T, E]], debug: bool = False\n) -&gt; Result[\n    Union[List[U], Tuple[Optional[List[U]], List[Tuple[str, Result[T, E]]]]], E\n]:\n    \"\"\"\n    Concurrently execute registered tasks with matching inputs.\n\n    Returns a list of outputs or a debug trace.\n    \"\"\"\n    if len(inputs) != len(self.tasks):\n        return Err(\"Number of inputs must match number of tasks\")\n\n    coros = [task(inp) for task, inp in zip(self.tasks, inputs)]\n    try:\n        results: List[Result[U, E]] = await asyncio.gather(*coros)\n    except Exception as e:\n        logger.exception(f\"[{self.name}] run() exception\")\n        return Err(str(e))\n\n    trace: List[Tuple[str, Result[T, E]]] = []\n    outputs: List[U] = []\n    for task, res in zip(self.tasks, results):\n        if debug:\n            trace.append((task.task_name, res))\n        if res.is_err():\n            if debug:\n                return Ok((None, trace))\n            return res\n        outputs.append(res.unwrap())\n    return Ok((outputs, trace)) if debug else Ok(outputs)\n</code></pre>"},{"location":"api/async_pipeline/#neopipe.async_pipeline.AsyncPipeline.run_parallel","title":"<code>run_parallel(pipelines, inputs, debug=False)</code>  <code>async</code> <code>staticmethod</code>","text":"<p>Execute multiple pipelines concurrently, each with its own input.</p> <p>Returns:</p> Type Description <code>Result[Union[List[PipelineResult], Tuple[Optional[List[PipelineResult]], PipelineTrace]], E]</code> <ul> <li>debug=False: Ok([PipelineResult, ...]) or Err(first_error)</li> </ul> <code>Result[Union[List[PipelineResult], Tuple[Optional[List[PipelineResult]], PipelineTrace]], E]</code> <ul> <li>debug=True : Ok((List[PipelineResult], PipelineTrace))</li> </ul> Source code in <code>neopipe/async_pipeline.py</code> <pre><code>@staticmethod\nasync def run_parallel(\n    pipelines: List[\"AsyncPipeline[T, E]\"],\n    inputs: List[Result[T, E]],\n    debug: bool = False,\n) -&gt; Result[\n    Union[\n        List[PipelineResult], Tuple[Optional[List[PipelineResult]], PipelineTrace]\n    ],\n    E,\n]:\n    \"\"\"\n    Execute multiple pipelines concurrently, each with its own input.\n\n    Returns:\n        - debug=False: Ok([PipelineResult, ...]) or Err(first_error)\n        - debug=True : Ok((List[PipelineResult], PipelineTrace))\n    \"\"\"\n    if len(pipelines) != len(inputs):\n        raise AssertionError(\"Each pipeline must have a corresponding input Result\")\n\n    coros = [p.run_sequence(inp, debug) for p, inp in zip(pipelines, inputs)]\n    try:\n        results = await asyncio.gather(*coros)\n    except Exception as e:\n        logger.exception(\"run_parallel exception\")\n        return Err(str(e))\n\n    pipeline_results: List[PipelineResult] = []\n    all_traces: List[SinglePipelineTrace[E]] = []\n\n    for pipeline, res in zip(pipelines, results):\n        if res.is_err():\n            return res\n        if debug:\n            val, trace = res.unwrap()\n            pipeline_results.append(PipelineResult(name=pipeline.name, result=val))\n            all_traces.append(SinglePipelineTrace(name=pipeline.name, tasks=trace))\n        else:\n            pipeline_results.append(\n                PipelineResult(name=pipeline.name, result=res.unwrap())\n            )\n\n    if debug:\n        return Ok((pipeline_results, PipelineTrace(pipelines=all_traces)))\n    return Ok(pipeline_results)\n</code></pre>"},{"location":"api/async_pipeline/#neopipe.async_pipeline.AsyncPipeline.run_sequence","title":"<code>run_sequence(input_result, debug=False)</code>  <code>async</code>","text":"<p>Execute registered tasks in sequence.</p> Source code in <code>neopipe/async_pipeline.py</code> <pre><code>async def run_sequence(\n    self, input_result: Result[T, E], debug: bool = False\n) -&gt; Result[Union[U, Tuple[Optional[U], List[Tuple[str, Result[T, E]]]]], E]:\n    \"\"\"\n    Execute registered tasks in sequence.\n    \"\"\"\n    trace: List[Tuple[str, Result[Any, E]]] = []\n    current: Result[Any, E] = input_result\n    for task in self.tasks:\n        try:\n            res: Result[U, E] = await task(current)\n        except Exception as e:\n            logger.exception(\n                f\"[{self.name}] run_sequence exception in {task.task_name}\"\n            )\n            return Err(str(e))\n        trace.append((task.task_name, res))\n        if res.is_err():\n            if debug:\n                return Ok((None, trace))\n            return res\n        current = res  # type: ignore\n    final = current.unwrap()  # type: ignore\n    return Ok((final, trace)) if debug else Ok(final)\n</code></pre>"},{"location":"api/pipeline/","title":"Pipeline","text":""},{"location":"api/pipeline/#neopipe.pipeline.SyncPipeline","title":"<code>SyncPipeline</code>","text":"<p>               Bases: <code>Generic[T, E]</code></p> <p>A pipeline that executes BaseSyncTasks sequentially, passing Result[T, E] through each step.</p> <p>Attributes:</p> Name Type Description <code>tasks</code> <code>List[BaseSyncTask]</code> <p>Registered tasks.</p> <code>pipeline_id</code> <code>UUID</code> <p>Unique ID for the pipeline.</p> <code>name</code> <code>str</code> <p>Optional name for logging/debugging.</p> Source code in <code>neopipe/pipeline.py</code> <pre><code>class SyncPipeline(Generic[T, E]):\n    \"\"\"\n    A pipeline that executes BaseSyncTasks sequentially, passing Result[T, E] through each step.\n\n    Attributes:\n        tasks (List[BaseSyncTask]): Registered tasks.\n        pipeline_id (UUID): Unique ID for the pipeline.\n        name (str): Optional name for logging/debugging.\n    \"\"\"\n\n    def __init__(self, name: Optional[str] = None):\n        self.tasks: List[BaseSyncTask] = []\n        self.pipeline_id = uuid.uuid4()\n        self.name = name or f\"SyncPipeline-{self.pipeline_id}\"\n\n    @classmethod\n    def from_tasks(\n        cls, tasks: List[BaseSyncTask], name: Optional[str] = None\n    ) -&gt; \"SyncPipeline\":\n        pipeline = cls(name)\n        for task in tasks:\n            pipeline.add_task(task)\n        return pipeline\n\n    def add_task(self, task: BaseSyncTask) -&gt; None:\n        if not isinstance(task, BaseSyncTask):\n            raise TypeError(\n                f\"Only BaseSyncTask instances can be added. Got {type(task)}\"\n            )\n\n        sig = inspect.signature(task.execute)\n        params = list(sig.parameters.values())\n        non_self_params = [p for p in params if p.name != \"self\"]\n\n        if len(non_self_params) &lt; 1:\n            raise TypeError(\n                f\"Task '{task.task_name}' must define an 'execute(self, input_result: Result)' method \"\n                \"with at least one input parameter.\"\n            )\n\n        param = non_self_params[0]\n        if get_origin(param.annotation) is not Result:\n            raise TypeError(\n                f\"Task '{task.task_name}' first argument must be of type Result[T, E]. Found: {param.annotation}\"\n            )\n\n        self.tasks.append(task)\n\n    def run(\n        self, input_result: Result[T, E], debug: bool = False\n    ) -&gt; Union[Result[U, E], Result[Tuple[Optional[U], List[Tuple[str, Result]]], E]]:\n        \"\"\"\n        Run the pipeline sequentially.\n\n        Args:\n            input_result (Result): Initial input wrapped in Result.\n            debug (bool): If True, returns execution trace as well.\n\n        Returns:\n            Result: Final output or failure, with optional trace in debug mode.\n        \"\"\"\n        trace: List[Tuple[str, Result]] = []\n        result: Result = input_result\n\n        if debug:\n            trace.append((self.name, result))\n\n        logger.info(f\"[{self.name}] Starting with {len(self.tasks)} task(s)\")\n\n        for idx, task in enumerate(self.tasks):\n            task_name = task.task_name\n            logger.info(f\"[{self.name}] Task {idx + 1}/{len(self.tasks)} \u2192 {task_name}\")\n\n            try:\n                result = task(result)\n            except Exception as e:\n                logger.exception(f\"[{self.name}] Exception in task {task_name}\")\n                return Err(f\"Exception in task {task_name}: {e}\")\n\n            if debug:\n                trace.append((task_name, result))\n\n            if result.is_err():\n                logger.error(f\"[{self.name}] Failed at {task_name}: {result.err()}\")\n                return Ok((None, trace)) if debug else result\n\n        logger.info(f\"[{self.name}] Completed successfully\")\n        return result if not debug else Ok((result.unwrap(), trace))\n\n    @staticmethod\n    def run_parallel(\n        pipelines: List[\"SyncPipeline[T, E]\"],\n        inputs: List[Result[T, E]],\n        max_workers: int = 4,\n        debug: bool = False,\n    ) -&gt; Result[\n        Union[\n            List[PipelineResult[U]], Tuple[List[PipelineResult[U]], PipelineTrace[E]]\n        ],\n        E,\n    ]:\n        \"\"\"\n        Execute multiple SyncPipelines in parallel threads.\n\n        Args:\n            pipelines: one SyncPipeline per thread\n            inputs:    initial Result[T, E] for each pipeline\n            max_workers: size of thread pool\n            debug: whether to capture per-pipeline, per-task traces\n\n        Returns:\n            - debug=False: Ok([PipelineResult(name, result), ...])\n            - debug=True:  Ok(( [PipelineResult(...)], PipelineTrace(\u2026)))\n            - Err on first pipeline failure or unhandled exception.\n        \"\"\"\n        if len(pipelines) != len(inputs):\n            raise AssertionError(\"Each pipeline needs a corresponding input Result\")\n\n        results: List[PipelineResult[U]] = [None] * len(pipelines)\n        traces: List[SinglePipelineTrace[E]] = []\n\n        with ThreadPoolExecutor(max_workers=max_workers) as pool:\n            future_to_idx = {\n                pool.submit(p.run, inp, debug): idx\n                for idx, (p, inp) in enumerate(zip(pipelines, inputs))\n            }\n\n            for fut in as_completed(future_to_idx):\n                idx = future_to_idx[fut]\n                pipe = pipelines[idx]\n\n                try:\n                    res = fut.result()\n                except Exception as ex:\n                    logger.exception(f\"[{pipe.name}] Unhandled exception\")\n                    return Err(f\"Exception in pipeline '{pipe.name}': {ex}\")\n\n                if res.is_err():\n                    logger.error(f\"[{pipe.name}] Failed: {res.err()}\")\n                    return Err(res.err())\n\n                # unwrap the Result from run(...)\n                if debug:\n                    val, trace = res.unwrap()  # (output, trace_list)\n                    results[idx] = PipelineResult(name=pipe.name, result=val)\n                    traces.append(SinglePipelineTrace(name=pipe.name, tasks=trace))\n                else:\n                    val = res.unwrap()\n                    results[idx] = PipelineResult(name=pipe.name, result=val)\n\n        if debug:\n            return Ok((results, PipelineTrace(pipelines=traces)))\n        return Ok(results)\n\n    def __str__(self) -&gt; str:\n        task_list = \"\\n  \".join(task.task_name for task in self.tasks)\n        return f\"{self.name} with {len(self.tasks)} task(s):\\n  {task_list}\"\n\n    def __repr__(self) -&gt; str:\n        return self.__str__()\n</code></pre>"},{"location":"api/pipeline/#neopipe.pipeline.SyncPipeline.run","title":"<code>run(input_result, debug=False)</code>","text":"<p>Run the pipeline sequentially.</p> <p>Parameters:</p> Name Type Description Default <code>input_result</code> <code>Result</code> <p>Initial input wrapped in Result.</p> required <code>debug</code> <code>bool</code> <p>If True, returns execution trace as well.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Result</code> <code>Union[Result[U, E], Result[Tuple[Optional[U], List[Tuple[str, Result]]], E]]</code> <p>Final output or failure, with optional trace in debug mode.</p> Source code in <code>neopipe/pipeline.py</code> <pre><code>def run(\n    self, input_result: Result[T, E], debug: bool = False\n) -&gt; Union[Result[U, E], Result[Tuple[Optional[U], List[Tuple[str, Result]]], E]]:\n    \"\"\"\n    Run the pipeline sequentially.\n\n    Args:\n        input_result (Result): Initial input wrapped in Result.\n        debug (bool): If True, returns execution trace as well.\n\n    Returns:\n        Result: Final output or failure, with optional trace in debug mode.\n    \"\"\"\n    trace: List[Tuple[str, Result]] = []\n    result: Result = input_result\n\n    if debug:\n        trace.append((self.name, result))\n\n    logger.info(f\"[{self.name}] Starting with {len(self.tasks)} task(s)\")\n\n    for idx, task in enumerate(self.tasks):\n        task_name = task.task_name\n        logger.info(f\"[{self.name}] Task {idx + 1}/{len(self.tasks)} \u2192 {task_name}\")\n\n        try:\n            result = task(result)\n        except Exception as e:\n            logger.exception(f\"[{self.name}] Exception in task {task_name}\")\n            return Err(f\"Exception in task {task_name}: {e}\")\n\n        if debug:\n            trace.append((task_name, result))\n\n        if result.is_err():\n            logger.error(f\"[{self.name}] Failed at {task_name}: {result.err()}\")\n            return Ok((None, trace)) if debug else result\n\n    logger.info(f\"[{self.name}] Completed successfully\")\n    return result if not debug else Ok((result.unwrap(), trace))\n</code></pre>"},{"location":"api/pipeline/#neopipe.pipeline.SyncPipeline.run_parallel","title":"<code>run_parallel(pipelines, inputs, max_workers=4, debug=False)</code>  <code>staticmethod</code>","text":"<p>Execute multiple SyncPipelines in parallel threads.</p> <p>Parameters:</p> Name Type Description Default <code>pipelines</code> <code>List[SyncPipeline[T, E]]</code> <p>one SyncPipeline per thread</p> required <code>inputs</code> <code>List[Result[T, E]]</code> <p>initial Result[T, E] for each pipeline</p> required <code>max_workers</code> <code>int</code> <p>size of thread pool</p> <code>4</code> <code>debug</code> <code>bool</code> <p>whether to capture per-pipeline, per-task traces</p> <code>False</code> <p>Returns:</p> Type Description <code>Result[Union[List[PipelineResult[U]], Tuple[List[PipelineResult[U]], PipelineTrace[E]]], E]</code> <ul> <li>debug=False: Ok([PipelineResult(name, result), ...])</li> </ul> <code>Result[Union[List[PipelineResult[U]], Tuple[List[PipelineResult[U]], PipelineTrace[E]]], E]</code> <ul> <li>debug=True:  Ok(( [PipelineResult(...)], PipelineTrace(\u2026)))</li> </ul> <code>Result[Union[List[PipelineResult[U]], Tuple[List[PipelineResult[U]], PipelineTrace[E]]], E]</code> <ul> <li>Err on first pipeline failure or unhandled exception.</li> </ul> Source code in <code>neopipe/pipeline.py</code> <pre><code>@staticmethod\ndef run_parallel(\n    pipelines: List[\"SyncPipeline[T, E]\"],\n    inputs: List[Result[T, E]],\n    max_workers: int = 4,\n    debug: bool = False,\n) -&gt; Result[\n    Union[\n        List[PipelineResult[U]], Tuple[List[PipelineResult[U]], PipelineTrace[E]]\n    ],\n    E,\n]:\n    \"\"\"\n    Execute multiple SyncPipelines in parallel threads.\n\n    Args:\n        pipelines: one SyncPipeline per thread\n        inputs:    initial Result[T, E] for each pipeline\n        max_workers: size of thread pool\n        debug: whether to capture per-pipeline, per-task traces\n\n    Returns:\n        - debug=False: Ok([PipelineResult(name, result), ...])\n        - debug=True:  Ok(( [PipelineResult(...)], PipelineTrace(\u2026)))\n        - Err on first pipeline failure or unhandled exception.\n    \"\"\"\n    if len(pipelines) != len(inputs):\n        raise AssertionError(\"Each pipeline needs a corresponding input Result\")\n\n    results: List[PipelineResult[U]] = [None] * len(pipelines)\n    traces: List[SinglePipelineTrace[E]] = []\n\n    with ThreadPoolExecutor(max_workers=max_workers) as pool:\n        future_to_idx = {\n            pool.submit(p.run, inp, debug): idx\n            for idx, (p, inp) in enumerate(zip(pipelines, inputs))\n        }\n\n        for fut in as_completed(future_to_idx):\n            idx = future_to_idx[fut]\n            pipe = pipelines[idx]\n\n            try:\n                res = fut.result()\n            except Exception as ex:\n                logger.exception(f\"[{pipe.name}] Unhandled exception\")\n                return Err(f\"Exception in pipeline '{pipe.name}': {ex}\")\n\n            if res.is_err():\n                logger.error(f\"[{pipe.name}] Failed: {res.err()}\")\n                return Err(res.err())\n\n            # unwrap the Result from run(...)\n            if debug:\n                val, trace = res.unwrap()  # (output, trace_list)\n                results[idx] = PipelineResult(name=pipe.name, result=val)\n                traces.append(SinglePipelineTrace(name=pipe.name, tasks=trace))\n            else:\n                val = res.unwrap()\n                results[idx] = PipelineResult(name=pipe.name, result=val)\n\n    if debug:\n        return Ok((results, PipelineTrace(pipelines=traces)))\n    return Ok(results)\n</code></pre>"},{"location":"api/result/","title":"Result","text":""},{"location":"api/result/#neopipe.result.PipelineResult","title":"<code>PipelineResult</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Generic[U]</code></p> <p>Represents the final outcome of a single pipeline run.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the pipeline.</p> <code>result</code> <code>U</code> <p>The final output value of type U.</p> Source code in <code>neopipe/result.py</code> <pre><code>@dataclass\nclass PipelineResult(Generic[U]):\n    \"\"\"\n    Represents the final outcome of a single pipeline run.\n\n    Attributes:\n        name: Name of the pipeline.\n        result: The final output value of type U.\n    \"\"\"\n\n    name: str\n    result: U\n</code></pre>"},{"location":"api/result/#neopipe.result.PipelineTrace","title":"<code>PipelineTrace</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Generic[E]</code></p> <p>Aggregates traces from multiple pipelines.</p> <p>Attributes:</p> Name Type Description <code>pipelines</code> <code>List[SinglePipelineTrace[E]]</code> <p>A list of SinglePipelineTrace instances.</p> Source code in <code>neopipe/result.py</code> <pre><code>@dataclass\nclass PipelineTrace(Generic[E]):\n    \"\"\"\n    Aggregates traces from multiple pipelines.\n\n    Attributes:\n        pipelines: A list of SinglePipelineTrace instances.\n    \"\"\"\n\n    pipelines: List[SinglePipelineTrace[E]]\n</code></pre>"},{"location":"api/result/#neopipe.result.Result","title":"<code>Result</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Generic[T, E]</code></p> <p>A Rust-style Result type for monadic error handling in Python.</p> Source code in <code>neopipe/result.py</code> <pre><code>@dataclass(frozen=True)\nclass Result(Generic[T, E]):\n    \"\"\"A Rust-style Result type for monadic error handling in Python.\"\"\"\n\n    _is_ok: bool\n    _value: Union[T, E]\n\n    @staticmethod\n    def Ok(value: T) -&gt; Self:\n        \"\"\"\n        Create a Result representing a successful value.\n\n        Args:\n            value: The success value.\n\n        Returns:\n            Result[T, E]: An Ok variant.\n        \"\"\"\n        return Result(True, value)\n\n    @staticmethod\n    def Err(error: E) -&gt; Self:\n        \"\"\"\n        Create a Result representing an error.\n\n        Args:\n            error: The error value.\n\n        Returns:\n            Result[T, E]: An Err variant.\n        \"\"\"\n        return Result(False, error)\n\n    def is_ok(self) -&gt; bool:\n        \"\"\"\n        Check if the result is Ok.\n\n        Returns:\n            bool: True if Ok, False otherwise.\n        \"\"\"\n        return self._is_ok\n\n    def is_err(self) -&gt; bool:\n        \"\"\"\n        Check if the result is Err.\n\n        Returns:\n            bool: True if Err, False otherwise.\n        \"\"\"\n        return not self._is_ok\n\n    def ok(self) -&gt; Union[T, None]:\n        \"\"\"\n        Get the success value if available.\n\n        Returns:\n            T | None: The Ok value or None.\n        \"\"\"\n        return self._value if self._is_ok else None\n\n    def err(self) -&gt; Union[E, None]:\n        \"\"\"\n        Get the error value if available.\n\n        Returns:\n            E | None: The Err value or None.\n        \"\"\"\n        return self._value if not self._is_ok else None\n\n    def map(self, op: Callable[[T], U]) -&gt; Result[U, E]:\n        \"\"\"\n        Apply a function to the Ok value.\n\n        Args:\n            op: A function that transforms the success value.\n\n        Returns:\n            Result[U, E]: A new Result with transformed success or the original error.\n        \"\"\"\n        if self._is_ok:\n            return Result.Ok(op(self._value))  # type: ignore\n        return Result.Err(self._value)  # type: ignore\n\n    async def map_async(self, op: Callable[[T], Awaitable[U]]) -&gt; Result[U, E]:\n        \"\"\"\n        Asynchronously apply a function to the Ok value.\n\n        Args:\n            op: An async function that transforms the success value.\n\n        Returns:\n            Result[U, E]: A new Result with transformed success or the original error.\n        \"\"\"\n        if self._is_ok:\n            return Result.Ok(await op(self._value))  # type: ignore\n        return Result.Err(self._value)  # type: ignore\n\n    def map_err(self, op: Callable[[E], U]) -&gt; Result[T, U]:\n        \"\"\"\n        Apply a function to the Err value.\n\n        Args:\n            op: A function that transforms the error value.\n\n        Returns:\n            Result[T, U]: A new Result with transformed error or the original success.\n        \"\"\"\n        if self._is_ok:\n            return Result.Ok(self._value)  # type: ignore\n        return Result.Err(op(self._value))  # type: ignore\n\n    async def map_err_async(self, op: Callable[[E], Awaitable[U]]) -&gt; Result[T, U]:\n        \"\"\"\n        Asynchronously apply a function to the Err value.\n\n        Args:\n            op: An async function that transforms the error value.\n\n        Returns:\n            Result[T, U]: A new Result with transformed error or the original success.\n        \"\"\"\n        if self._is_ok:\n            return Result.Ok(self._value)  # type: ignore\n        return Result.Err(await op(self._value))  # type: ignore\n\n    def and_then(self, op: Callable[[T], Result[U, E]]) -&gt; Result[U, E]:\n        \"\"\"\n        Chain another Result-returning function if current is Ok.\n\n        Args:\n            op: A function that takes a success value and returns a new Result.\n\n        Returns:\n            Result[U, E]: The new chained result, or the original error.\n        \"\"\"\n        if self._is_ok:\n            return op(self._value)  # type: ignore\n        return Result.Err(self._value)  # type: ignore\n\n    async def and_then_async(\n        self, op: Callable[[T], Awaitable[Result[U, E]]]\n    ) -&gt; Result[U, E]:\n        \"\"\"\n        Asynchronously chain another Result-returning function if current is Ok.\n\n        Args:\n            op: An async function that takes a success value and returns a new Result.\n\n        Returns:\n            Result[U, E]: The new chained result, or the original error.\n        \"\"\"\n        if self._is_ok:\n            return await op(self._value)  # type: ignore\n        return Result.Err(self._value)  # type: ignore\n\n    def unwrap(self) -&gt; T:\n        \"\"\"\n        Extract the success value or raise an error.\n\n        Returns:\n            T: The Ok value.\n\n        Raises:\n            UnwrapError: If the result is Err.\n        \"\"\"\n        if self._is_ok:\n            return self._value  # type: ignore\n        raise UnwrapError(f\"Called unwrap on Err: {self._value}\")\n\n    def unwrap_or(self, default: T) -&gt; T:\n        \"\"\"\n        Return the success value or a default.\n\n        Args:\n            default: The fallback value.\n\n        Returns:\n            T: The Ok value or the default.\n        \"\"\"\n        return self._value if self._is_ok else default  # type: ignore\n\n    def unwrap_or_else(self, op: Callable[[E], T]) -&gt; T:\n        \"\"\"\n        Return the success value or a value generated from the error.\n\n        Args:\n            op: A function that maps the error to a fallback value.\n\n        Returns:\n            T: The Ok value or a fallback derived from the error.\n        \"\"\"\n        return self._value if self._is_ok else op(self._value)  # type: ignore\n\n    def expect(self, msg: str) -&gt; T:\n        \"\"\"\n        Extract the success value or raise with a custom message.\n\n        Args:\n            msg: The message to include in the exception.\n\n        Returns:\n            T: The Ok value.\n\n        Raises:\n            UnwrapError: If the result is Err.\n        \"\"\"\n        if self._is_ok:\n            return self._value  # type: ignore\n        raise UnwrapError(f\"{msg}: {self._value}\")\n\n    def match(self, ok_fn: Callable[[T], U], err_fn: Callable[[E], U]) -&gt; U:\n        \"\"\"\n        Pattern match to handle both Ok and Err branches.\n\n        Args:\n            ok_fn: Function to handle Ok.\n            err_fn: Function to handle Err.\n\n        Returns:\n            U: Result of executing the appropriate handler.\n        \"\"\"\n        if self._is_ok:\n            return ok_fn(self._value)  # type: ignore\n        return err_fn(self._value)  # type: ignore\n\n    def to_dict(self) -&gt; dict:\n        \"\"\"Converts the Result to a dictionary.\n\n        Returns:\n            dict: The Result as a dictionary\n        \"\"\"\n        return asdict(self)\n\n    def to_json(self) -&gt; str:\n        \"\"\"Converts the Result to a JSON string.\n\n        Returns:\n            str: The Result as a JSON string\n        \"\"\"\n        return json.dumps(self.to_dict())\n\n    def __repr__(self) -&gt; str:\n        \"\"\"\n        Return a string representation of the Result.\n\n        Returns:\n            str: Ok(value) or Err(error).\n        \"\"\"\n        variant = \"Ok\" if self._is_ok else \"Err\"\n        return f\"{variant}({self._value!r})\"\n</code></pre>"},{"location":"api/result/#neopipe.result.Result.Err","title":"<code>Err(error)</code>  <code>staticmethod</code>","text":"<p>Create a Result representing an error.</p> <p>Parameters:</p> Name Type Description Default <code>error</code> <code>E</code> <p>The error value.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>Result[T, E]: An Err variant.</p> Source code in <code>neopipe/result.py</code> <pre><code>@staticmethod\ndef Err(error: E) -&gt; Self:\n    \"\"\"\n    Create a Result representing an error.\n\n    Args:\n        error: The error value.\n\n    Returns:\n        Result[T, E]: An Err variant.\n    \"\"\"\n    return Result(False, error)\n</code></pre>"},{"location":"api/result/#neopipe.result.Result.Ok","title":"<code>Ok(value)</code>  <code>staticmethod</code>","text":"<p>Create a Result representing a successful value.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>T</code> <p>The success value.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>Result[T, E]: An Ok variant.</p> Source code in <code>neopipe/result.py</code> <pre><code>@staticmethod\ndef Ok(value: T) -&gt; Self:\n    \"\"\"\n    Create a Result representing a successful value.\n\n    Args:\n        value: The success value.\n\n    Returns:\n        Result[T, E]: An Ok variant.\n    \"\"\"\n    return Result(True, value)\n</code></pre>"},{"location":"api/result/#neopipe.result.Result.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a string representation of the Result.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Ok(value) or Err(error).</p> Source code in <code>neopipe/result.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"\n    Return a string representation of the Result.\n\n    Returns:\n        str: Ok(value) or Err(error).\n    \"\"\"\n    variant = \"Ok\" if self._is_ok else \"Err\"\n    return f\"{variant}({self._value!r})\"\n</code></pre>"},{"location":"api/result/#neopipe.result.Result.and_then","title":"<code>and_then(op)</code>","text":"<p>Chain another Result-returning function if current is Ok.</p> <p>Parameters:</p> Name Type Description Default <code>op</code> <code>Callable[[T], Result[U, E]]</code> <p>A function that takes a success value and returns a new Result.</p> required <p>Returns:</p> Type Description <code>Result[U, E]</code> <p>Result[U, E]: The new chained result, or the original error.</p> Source code in <code>neopipe/result.py</code> <pre><code>def and_then(self, op: Callable[[T], Result[U, E]]) -&gt; Result[U, E]:\n    \"\"\"\n    Chain another Result-returning function if current is Ok.\n\n    Args:\n        op: A function that takes a success value and returns a new Result.\n\n    Returns:\n        Result[U, E]: The new chained result, or the original error.\n    \"\"\"\n    if self._is_ok:\n        return op(self._value)  # type: ignore\n    return Result.Err(self._value)  # type: ignore\n</code></pre>"},{"location":"api/result/#neopipe.result.Result.and_then_async","title":"<code>and_then_async(op)</code>  <code>async</code>","text":"<p>Asynchronously chain another Result-returning function if current is Ok.</p> <p>Parameters:</p> Name Type Description Default <code>op</code> <code>Callable[[T], Awaitable[Result[U, E]]]</code> <p>An async function that takes a success value and returns a new Result.</p> required <p>Returns:</p> Type Description <code>Result[U, E]</code> <p>Result[U, E]: The new chained result, or the original error.</p> Source code in <code>neopipe/result.py</code> <pre><code>async def and_then_async(\n    self, op: Callable[[T], Awaitable[Result[U, E]]]\n) -&gt; Result[U, E]:\n    \"\"\"\n    Asynchronously chain another Result-returning function if current is Ok.\n\n    Args:\n        op: An async function that takes a success value and returns a new Result.\n\n    Returns:\n        Result[U, E]: The new chained result, or the original error.\n    \"\"\"\n    if self._is_ok:\n        return await op(self._value)  # type: ignore\n    return Result.Err(self._value)  # type: ignore\n</code></pre>"},{"location":"api/result/#neopipe.result.Result.err","title":"<code>err()</code>","text":"<p>Get the error value if available.</p> <p>Returns:</p> Type Description <code>Union[E, None]</code> <p>E | None: The Err value or None.</p> Source code in <code>neopipe/result.py</code> <pre><code>def err(self) -&gt; Union[E, None]:\n    \"\"\"\n    Get the error value if available.\n\n    Returns:\n        E | None: The Err value or None.\n    \"\"\"\n    return self._value if not self._is_ok else None\n</code></pre>"},{"location":"api/result/#neopipe.result.Result.expect","title":"<code>expect(msg)</code>","text":"<p>Extract the success value or raise with a custom message.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>str</code> <p>The message to include in the exception.</p> required <p>Returns:</p> Name Type Description <code>T</code> <code>T</code> <p>The Ok value.</p> <p>Raises:</p> Type Description <code>UnwrapError</code> <p>If the result is Err.</p> Source code in <code>neopipe/result.py</code> <pre><code>def expect(self, msg: str) -&gt; T:\n    \"\"\"\n    Extract the success value or raise with a custom message.\n\n    Args:\n        msg: The message to include in the exception.\n\n    Returns:\n        T: The Ok value.\n\n    Raises:\n        UnwrapError: If the result is Err.\n    \"\"\"\n    if self._is_ok:\n        return self._value  # type: ignore\n    raise UnwrapError(f\"{msg}: {self._value}\")\n</code></pre>"},{"location":"api/result/#neopipe.result.Result.is_err","title":"<code>is_err()</code>","text":"<p>Check if the result is Err.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if Err, False otherwise.</p> Source code in <code>neopipe/result.py</code> <pre><code>def is_err(self) -&gt; bool:\n    \"\"\"\n    Check if the result is Err.\n\n    Returns:\n        bool: True if Err, False otherwise.\n    \"\"\"\n    return not self._is_ok\n</code></pre>"},{"location":"api/result/#neopipe.result.Result.is_ok","title":"<code>is_ok()</code>","text":"<p>Check if the result is Ok.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if Ok, False otherwise.</p> Source code in <code>neopipe/result.py</code> <pre><code>def is_ok(self) -&gt; bool:\n    \"\"\"\n    Check if the result is Ok.\n\n    Returns:\n        bool: True if Ok, False otherwise.\n    \"\"\"\n    return self._is_ok\n</code></pre>"},{"location":"api/result/#neopipe.result.Result.map","title":"<code>map(op)</code>","text":"<p>Apply a function to the Ok value.</p> <p>Parameters:</p> Name Type Description Default <code>op</code> <code>Callable[[T], U]</code> <p>A function that transforms the success value.</p> required <p>Returns:</p> Type Description <code>Result[U, E]</code> <p>Result[U, E]: A new Result with transformed success or the original error.</p> Source code in <code>neopipe/result.py</code> <pre><code>def map(self, op: Callable[[T], U]) -&gt; Result[U, E]:\n    \"\"\"\n    Apply a function to the Ok value.\n\n    Args:\n        op: A function that transforms the success value.\n\n    Returns:\n        Result[U, E]: A new Result with transformed success or the original error.\n    \"\"\"\n    if self._is_ok:\n        return Result.Ok(op(self._value))  # type: ignore\n    return Result.Err(self._value)  # type: ignore\n</code></pre>"},{"location":"api/result/#neopipe.result.Result.map_async","title":"<code>map_async(op)</code>  <code>async</code>","text":"<p>Asynchronously apply a function to the Ok value.</p> <p>Parameters:</p> Name Type Description Default <code>op</code> <code>Callable[[T], Awaitable[U]]</code> <p>An async function that transforms the success value.</p> required <p>Returns:</p> Type Description <code>Result[U, E]</code> <p>Result[U, E]: A new Result with transformed success or the original error.</p> Source code in <code>neopipe/result.py</code> <pre><code>async def map_async(self, op: Callable[[T], Awaitable[U]]) -&gt; Result[U, E]:\n    \"\"\"\n    Asynchronously apply a function to the Ok value.\n\n    Args:\n        op: An async function that transforms the success value.\n\n    Returns:\n        Result[U, E]: A new Result with transformed success or the original error.\n    \"\"\"\n    if self._is_ok:\n        return Result.Ok(await op(self._value))  # type: ignore\n    return Result.Err(self._value)  # type: ignore\n</code></pre>"},{"location":"api/result/#neopipe.result.Result.map_err","title":"<code>map_err(op)</code>","text":"<p>Apply a function to the Err value.</p> <p>Parameters:</p> Name Type Description Default <code>op</code> <code>Callable[[E], U]</code> <p>A function that transforms the error value.</p> required <p>Returns:</p> Type Description <code>Result[T, U]</code> <p>Result[T, U]: A new Result with transformed error or the original success.</p> Source code in <code>neopipe/result.py</code> <pre><code>def map_err(self, op: Callable[[E], U]) -&gt; Result[T, U]:\n    \"\"\"\n    Apply a function to the Err value.\n\n    Args:\n        op: A function that transforms the error value.\n\n    Returns:\n        Result[T, U]: A new Result with transformed error or the original success.\n    \"\"\"\n    if self._is_ok:\n        return Result.Ok(self._value)  # type: ignore\n    return Result.Err(op(self._value))  # type: ignore\n</code></pre>"},{"location":"api/result/#neopipe.result.Result.map_err_async","title":"<code>map_err_async(op)</code>  <code>async</code>","text":"<p>Asynchronously apply a function to the Err value.</p> <p>Parameters:</p> Name Type Description Default <code>op</code> <code>Callable[[E], Awaitable[U]]</code> <p>An async function that transforms the error value.</p> required <p>Returns:</p> Type Description <code>Result[T, U]</code> <p>Result[T, U]: A new Result with transformed error or the original success.</p> Source code in <code>neopipe/result.py</code> <pre><code>async def map_err_async(self, op: Callable[[E], Awaitable[U]]) -&gt; Result[T, U]:\n    \"\"\"\n    Asynchronously apply a function to the Err value.\n\n    Args:\n        op: An async function that transforms the error value.\n\n    Returns:\n        Result[T, U]: A new Result with transformed error or the original success.\n    \"\"\"\n    if self._is_ok:\n        return Result.Ok(self._value)  # type: ignore\n    return Result.Err(await op(self._value))  # type: ignore\n</code></pre>"},{"location":"api/result/#neopipe.result.Result.match","title":"<code>match(ok_fn, err_fn)</code>","text":"<p>Pattern match to handle both Ok and Err branches.</p> <p>Parameters:</p> Name Type Description Default <code>ok_fn</code> <code>Callable[[T], U]</code> <p>Function to handle Ok.</p> required <code>err_fn</code> <code>Callable[[E], U]</code> <p>Function to handle Err.</p> required <p>Returns:</p> Name Type Description <code>U</code> <code>U</code> <p>Result of executing the appropriate handler.</p> Source code in <code>neopipe/result.py</code> <pre><code>def match(self, ok_fn: Callable[[T], U], err_fn: Callable[[E], U]) -&gt; U:\n    \"\"\"\n    Pattern match to handle both Ok and Err branches.\n\n    Args:\n        ok_fn: Function to handle Ok.\n        err_fn: Function to handle Err.\n\n    Returns:\n        U: Result of executing the appropriate handler.\n    \"\"\"\n    if self._is_ok:\n        return ok_fn(self._value)  # type: ignore\n    return err_fn(self._value)  # type: ignore\n</code></pre>"},{"location":"api/result/#neopipe.result.Result.ok","title":"<code>ok()</code>","text":"<p>Get the success value if available.</p> <p>Returns:</p> Type Description <code>Union[T, None]</code> <p>T | None: The Ok value or None.</p> Source code in <code>neopipe/result.py</code> <pre><code>def ok(self) -&gt; Union[T, None]:\n    \"\"\"\n    Get the success value if available.\n\n    Returns:\n        T | None: The Ok value or None.\n    \"\"\"\n    return self._value if self._is_ok else None\n</code></pre>"},{"location":"api/result/#neopipe.result.Result.to_dict","title":"<code>to_dict()</code>","text":"<p>Converts the Result to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The Result as a dictionary</p> Source code in <code>neopipe/result.py</code> <pre><code>def to_dict(self) -&gt; dict:\n    \"\"\"Converts the Result to a dictionary.\n\n    Returns:\n        dict: The Result as a dictionary\n    \"\"\"\n    return asdict(self)\n</code></pre>"},{"location":"api/result/#neopipe.result.Result.to_json","title":"<code>to_json()</code>","text":"<p>Converts the Result to a JSON string.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The Result as a JSON string</p> Source code in <code>neopipe/result.py</code> <pre><code>def to_json(self) -&gt; str:\n    \"\"\"Converts the Result to a JSON string.\n\n    Returns:\n        str: The Result as a JSON string\n    \"\"\"\n    return json.dumps(self.to_dict())\n</code></pre>"},{"location":"api/result/#neopipe.result.Result.unwrap","title":"<code>unwrap()</code>","text":"<p>Extract the success value or raise an error.</p> <p>Returns:</p> Name Type Description <code>T</code> <code>T</code> <p>The Ok value.</p> <p>Raises:</p> Type Description <code>UnwrapError</code> <p>If the result is Err.</p> Source code in <code>neopipe/result.py</code> <pre><code>def unwrap(self) -&gt; T:\n    \"\"\"\n    Extract the success value or raise an error.\n\n    Returns:\n        T: The Ok value.\n\n    Raises:\n        UnwrapError: If the result is Err.\n    \"\"\"\n    if self._is_ok:\n        return self._value  # type: ignore\n    raise UnwrapError(f\"Called unwrap on Err: {self._value}\")\n</code></pre>"},{"location":"api/result/#neopipe.result.Result.unwrap_or","title":"<code>unwrap_or(default)</code>","text":"<p>Return the success value or a default.</p> <p>Parameters:</p> Name Type Description Default <code>default</code> <code>T</code> <p>The fallback value.</p> required <p>Returns:</p> Name Type Description <code>T</code> <code>T</code> <p>The Ok value or the default.</p> Source code in <code>neopipe/result.py</code> <pre><code>def unwrap_or(self, default: T) -&gt; T:\n    \"\"\"\n    Return the success value or a default.\n\n    Args:\n        default: The fallback value.\n\n    Returns:\n        T: The Ok value or the default.\n    \"\"\"\n    return self._value if self._is_ok else default  # type: ignore\n</code></pre>"},{"location":"api/result/#neopipe.result.Result.unwrap_or_else","title":"<code>unwrap_or_else(op)</code>","text":"<p>Return the success value or a value generated from the error.</p> <p>Parameters:</p> Name Type Description Default <code>op</code> <code>Callable[[E], T]</code> <p>A function that maps the error to a fallback value.</p> required <p>Returns:</p> Name Type Description <code>T</code> <code>T</code> <p>The Ok value or a fallback derived from the error.</p> Source code in <code>neopipe/result.py</code> <pre><code>def unwrap_or_else(self, op: Callable[[E], T]) -&gt; T:\n    \"\"\"\n    Return the success value or a value generated from the error.\n\n    Args:\n        op: A function that maps the error to a fallback value.\n\n    Returns:\n        T: The Ok value or a fallback derived from the error.\n    \"\"\"\n    return self._value if self._is_ok else op(self._value)  # type: ignore\n</code></pre>"},{"location":"api/result/#neopipe.result.SinglePipelineTrace","title":"<code>SinglePipelineTrace</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Generic[E]</code></p> <p>Captures the per-step trace for one pipeline.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the pipeline.</p> <code>tasks</code> <code>List[Tuple[str, Result[Any, E]]]</code> <p>List of (task_name, Result) tuples for each step.</p> Source code in <code>neopipe/result.py</code> <pre><code>@dataclass\nclass SinglePipelineTrace(Generic[E]):\n    \"\"\"\n    Captures the per-step trace for one pipeline.\n\n    Attributes:\n        name: Name of the pipeline.\n        tasks: List of (task_name, Result) tuples for each step.\n    \"\"\"\n\n    name: str\n    tasks: List[Tuple[str, Result[Any, E]]]\n</code></pre>"},{"location":"api/result/#neopipe.result.UnwrapError","title":"<code>UnwrapError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when unwrap is called on an Err value.</p> Source code in <code>neopipe/result.py</code> <pre><code>class UnwrapError(Exception):\n    \"\"\"Raised when unwrap is called on an Err value.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/result/#neopipe.result.Err","title":"<code>Err(error)</code>","text":"<p>Creates an Err Result with the given error.</p> Source code in <code>neopipe/result.py</code> <pre><code>def Err(error: E) -&gt; Result[None, E]:\n    \"\"\"Creates an Err Result with the given error.\"\"\"\n    return Result(False, error)\n</code></pre>"},{"location":"api/result/#neopipe.result.Ok","title":"<code>Ok(value)</code>","text":"<p>Creates an Ok Result with the given value.</p> Source code in <code>neopipe/result.py</code> <pre><code>def Ok(value: T) -&gt; Result[T, None]:\n    \"\"\"Creates an Ok Result with the given value.\"\"\"\n    return Result(True, value)\n</code></pre>"},{"location":"api/task/","title":"Task","text":""},{"location":"api/task/#neopipe.task.BaseAsyncTask","title":"<code>BaseAsyncTask</code>","text":"<p>               Bases: <code>ABC</code>, <code>Generic[T, E]</code></p> <p>Abstract base class for async tasks that operate entirely on Result[T, E].</p> <p>Each task receives a Result, processes it (if Ok), and returns a new Result.</p> Source code in <code>neopipe/task.py</code> <pre><code>class BaseAsyncTask(ABC, Generic[T, E]):\n    \"\"\"\n    Abstract base class for async tasks that operate entirely on Result[T, E].\n\n    Each task receives a Result, processes it (if Ok), and returns a new Result.\n    \"\"\"\n\n    def __init__(self, retries: int = 1):\n        self.retries = retries\n        self.task_id = uuid.uuid4()\n\n    @property\n    def task_name(self) -&gt; str:\n        \"\"\"Returns a human-readable task name.\"\"\"\n        return self.__class__.__name__\n\n    async def __call__(self, input_result: Result[T, E]) -&gt; Result[U, E]:\n        \"\"\"\n        Executes the task with retry logic.\n\n        Args:\n            input_result (Result[T, E]): The input Result from a previous task.\n\n        Returns:\n            Result[U, E]: Final task result after retry handling.\n        \"\"\"\n        last_exception: Optional[Exception] = None\n\n        for attempt in range(1, self.retries + 1):\n            try:\n                logger.info(\n                    f\"[{self.task_name}] Attempt {attempt} - Task ID: {self.task_id}\"\n                )\n                result = await self.execute(input_result)\n\n                if result.is_ok():\n                    logger.info(f\"[{self.task_name}] Success on attempt {attempt}\")\n                    return result\n                else:\n                    logger.warning(f\"[{self.task_name}] Returned Err: {result.err()}\")\n                    return result\n\n            except Exception as e:\n                last_exception = e\n                logger.exception(f\"[{self.task_name}] Exception on attempt {attempt}\")\n                await asyncio.sleep(2 ** (attempt - 1))  # exponential backoff\n        # tb = traceback.format_exception(\n        #     last_exception.__class__, last_exception, last_exception.__traceback__\n        # )\n        return Err(\n            f\"[{self.task_name}] failed after {self.retries} retries and raised Error: {last_exception} with Exception type: {last_exception.__class__.__name__}.\"\n        )\n\n    @abstractmethod\n    async def execute(self, input_result: Result[T, E]) -&gt; Result[U, E]:\n        \"\"\"\n        Async task execution logic that must be overridden.\n\n        Args:\n            input_result (Result[T, E]): The input Result.\n\n        Returns:\n            Result[U, E]: The output Result.\n        \"\"\"\n        pass\n\n    def __str__(self) -&gt; str:\n        return f\"{self.task_name}(ID={self.task_id})\"\n\n    def __repr__(self) -&gt; str:\n        return self.__str__()\n</code></pre>"},{"location":"api/task/#neopipe.task.BaseAsyncTask.task_name","title":"<code>task_name</code>  <code>property</code>","text":"<p>Returns a human-readable task name.</p>"},{"location":"api/task/#neopipe.task.BaseAsyncTask.__call__","title":"<code>__call__(input_result)</code>  <code>async</code>","text":"<p>Executes the task with retry logic.</p> <p>Parameters:</p> Name Type Description Default <code>input_result</code> <code>Result[T, E]</code> <p>The input Result from a previous task.</p> required <p>Returns:</p> Type Description <code>Result[U, E]</code> <p>Result[U, E]: Final task result after retry handling.</p> Source code in <code>neopipe/task.py</code> <pre><code>async def __call__(self, input_result: Result[T, E]) -&gt; Result[U, E]:\n    \"\"\"\n    Executes the task with retry logic.\n\n    Args:\n        input_result (Result[T, E]): The input Result from a previous task.\n\n    Returns:\n        Result[U, E]: Final task result after retry handling.\n    \"\"\"\n    last_exception: Optional[Exception] = None\n\n    for attempt in range(1, self.retries + 1):\n        try:\n            logger.info(\n                f\"[{self.task_name}] Attempt {attempt} - Task ID: {self.task_id}\"\n            )\n            result = await self.execute(input_result)\n\n            if result.is_ok():\n                logger.info(f\"[{self.task_name}] Success on attempt {attempt}\")\n                return result\n            else:\n                logger.warning(f\"[{self.task_name}] Returned Err: {result.err()}\")\n                return result\n\n        except Exception as e:\n            last_exception = e\n            logger.exception(f\"[{self.task_name}] Exception on attempt {attempt}\")\n            await asyncio.sleep(2 ** (attempt - 1))  # exponential backoff\n    # tb = traceback.format_exception(\n    #     last_exception.__class__, last_exception, last_exception.__traceback__\n    # )\n    return Err(\n        f\"[{self.task_name}] failed after {self.retries} retries and raised Error: {last_exception} with Exception type: {last_exception.__class__.__name__}.\"\n    )\n</code></pre>"},{"location":"api/task/#neopipe.task.BaseAsyncTask.execute","title":"<code>execute(input_result)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Async task execution logic that must be overridden.</p> <p>Parameters:</p> Name Type Description Default <code>input_result</code> <code>Result[T, E]</code> <p>The input Result.</p> required <p>Returns:</p> Type Description <code>Result[U, E]</code> <p>Result[U, E]: The output Result.</p> Source code in <code>neopipe/task.py</code> <pre><code>@abstractmethod\nasync def execute(self, input_result: Result[T, E]) -&gt; Result[U, E]:\n    \"\"\"\n    Async task execution logic that must be overridden.\n\n    Args:\n        input_result (Result[T, E]): The input Result.\n\n    Returns:\n        Result[U, E]: The output Result.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/task/#neopipe.task.BaseSyncTask","title":"<code>BaseSyncTask</code>","text":"<p>               Bases: <code>ABC</code>, <code>Generic[T, E]</code></p> <p>Abstract base class for synchronous tasks that operate entirely on Result[T, E].</p> <p>Each task receives a Result object, processes it (if Ok), and returns a new Result. Retry logic, logging, and task identification are handled automatically.</p> <p>Attributes:</p> Name Type Description <code>retries</code> <code>int</code> <p>Number of retry attempts if execution fails.</p> <code>task_id</code> <code>UUID</code> <p>Unique identifier for the task instance.</p> Source code in <code>neopipe/task.py</code> <pre><code>class BaseSyncTask(ABC, Generic[T, E]):\n    \"\"\"\n    Abstract base class for synchronous tasks that operate entirely on Result[T, E].\n\n    Each task receives a Result object, processes it (if Ok), and returns a new Result.\n    Retry logic, logging, and task identification are handled automatically.\n\n    Attributes:\n        retries (int): Number of retry attempts if execution fails.\n        task_id (UUID): Unique identifier for the task instance.\n    \"\"\"\n\n    def __init__(self, retries: int = 1):\n        self.retries = retries\n        self.task_id = uuid.uuid4()\n\n    @property\n    def task_name(self) -&gt; str:\n        \"\"\"Returns a human-readable task name.\"\"\"\n        return self.__class__.__name__\n\n    def __call__(self, input_result: Result[T, E]) -&gt; Result[U, E]:\n        \"\"\"\n        Executes the task with retry logic.\n\n        Args:\n            input_result (Result[T, E]): The input wrapped in a Result.\n\n        Returns:\n            Result[U, E]: The result of the task, either Ok or Err.\n        \"\"\"\n        last_exception: Optional[Exception] = None\n\n        for attempt in range(1, self.retries + 1):\n            try:\n                logger.info(\n                    f\"[{self.task_name}] Attempt {attempt} - Task ID: {self.task_id}\"\n                )\n                result = self.execute(input_result)\n\n                if result.is_ok():\n                    logger.info(f\"[{self.task_name}] Success on attempt {attempt}\")\n                    return result\n                else:\n                    logger.error(f\"[{self.task_name}] Returned Err: {result.err()}\")\n                    return result\n\n            except Exception as e:\n                last_exception = e\n                logger.exception(f\"[{self.task_name}] Exception on attempt {attempt}\")\n                time.sleep(2 ** (attempt - 1))  # Exponential backoff\n\n        return Err(\n            f\"[{self.task_name}] failed after {self.retries} retries and raised Error: {last_exception} with Exception type: {last_exception.__class__.__name__}.\"\n        )\n\n    @abstractmethod\n    def execute(self, input_result: Result[T, E]) -&gt; Result[U, E]:\n        \"\"\"\n        Override this method in subclasses or function wrappers.\n\n        Args:\n            input_result (Result[T, E]): The input wrapped in a Result.\n\n        Returns:\n            Result[U, E]: The transformed output.\n        \"\"\"\n        pass\n\n    def __str__(self) -&gt; str:\n        return f\"{self.task_name}(ID={self.task_id})\"\n\n    def __repr__(self) -&gt; str:\n        return self.__str__()\n</code></pre>"},{"location":"api/task/#neopipe.task.BaseSyncTask.task_name","title":"<code>task_name</code>  <code>property</code>","text":"<p>Returns a human-readable task name.</p>"},{"location":"api/task/#neopipe.task.BaseSyncTask.__call__","title":"<code>__call__(input_result)</code>","text":"<p>Executes the task with retry logic.</p> <p>Parameters:</p> Name Type Description Default <code>input_result</code> <code>Result[T, E]</code> <p>The input wrapped in a Result.</p> required <p>Returns:</p> Type Description <code>Result[U, E]</code> <p>Result[U, E]: The result of the task, either Ok or Err.</p> Source code in <code>neopipe/task.py</code> <pre><code>def __call__(self, input_result: Result[T, E]) -&gt; Result[U, E]:\n    \"\"\"\n    Executes the task with retry logic.\n\n    Args:\n        input_result (Result[T, E]): The input wrapped in a Result.\n\n    Returns:\n        Result[U, E]: The result of the task, either Ok or Err.\n    \"\"\"\n    last_exception: Optional[Exception] = None\n\n    for attempt in range(1, self.retries + 1):\n        try:\n            logger.info(\n                f\"[{self.task_name}] Attempt {attempt} - Task ID: {self.task_id}\"\n            )\n            result = self.execute(input_result)\n\n            if result.is_ok():\n                logger.info(f\"[{self.task_name}] Success on attempt {attempt}\")\n                return result\n            else:\n                logger.error(f\"[{self.task_name}] Returned Err: {result.err()}\")\n                return result\n\n        except Exception as e:\n            last_exception = e\n            logger.exception(f\"[{self.task_name}] Exception on attempt {attempt}\")\n            time.sleep(2 ** (attempt - 1))  # Exponential backoff\n\n    return Err(\n        f\"[{self.task_name}] failed after {self.retries} retries and raised Error: {last_exception} with Exception type: {last_exception.__class__.__name__}.\"\n    )\n</code></pre>"},{"location":"api/task/#neopipe.task.BaseSyncTask.execute","title":"<code>execute(input_result)</code>  <code>abstractmethod</code>","text":"<p>Override this method in subclasses or function wrappers.</p> <p>Parameters:</p> Name Type Description Default <code>input_result</code> <code>Result[T, E]</code> <p>The input wrapped in a Result.</p> required <p>Returns:</p> Type Description <code>Result[U, E]</code> <p>Result[U, E]: The transformed output.</p> Source code in <code>neopipe/task.py</code> <pre><code>@abstractmethod\ndef execute(self, input_result: Result[T, E]) -&gt; Result[U, E]:\n    \"\"\"\n    Override this method in subclasses or function wrappers.\n\n    Args:\n        input_result (Result[T, E]): The input wrapped in a Result.\n\n    Returns:\n        Result[U, E]: The transformed output.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/task/#neopipe.task.ClassAsyncTask","title":"<code>ClassAsyncTask</code>","text":"<p>               Bases: <code>BaseAsyncTask[T, E]</code>, <code>ABC</code></p> <p>Extend this class to define custom async tasks that operate on Result[T, E].</p> Example <p>class MultiplyTask(ClassAsyncTask[int, str]):     def init(self, factor: int):         super().init()         self.factor = factor</p> <pre><code>async def execute(self, input_result: Result[int, str]) -&gt; Result[int, str]:\n    if input_result.is_ok():\n        return Ok(input_result.unwrap() * self.factor)\n    return input_result\n</code></pre> Source code in <code>neopipe/task.py</code> <pre><code>class ClassAsyncTask(BaseAsyncTask[T, E], ABC):\n    \"\"\"\n    Extend this class to define custom async tasks that operate on Result[T, E].\n\n    Example:\n        class MultiplyTask(ClassAsyncTask[int, str]):\n            def __init__(self, factor: int):\n                super().__init__()\n                self.factor = factor\n\n            async def execute(self, input_result: Result[int, str]) -&gt; Result[int, str]:\n                if input_result.is_ok():\n                    return Ok(input_result.unwrap() * self.factor)\n                return input_result\n    \"\"\"\n\n    def __init__(self, retries: int = 1):\n        super().__init__(retries)\n</code></pre>"},{"location":"api/task/#neopipe.task.ClassSyncTask","title":"<code>ClassSyncTask</code>","text":"<p>               Bases: <code>BaseSyncTask[T, E]</code>, <code>ABC</code></p> <p>Extend this class to create stateful or configurable sync tasks.</p> <p>You must override the <code>execute(self, input_result: Result[T, E])</code> method.</p> Example <p>class MultiplyTask(ClassSyncTask[int, str]):     def init(self, factor: int):         super().init()         self.factor = factor</p> <pre><code>def execute(self, input_result: Result[int, str]) -&gt; Result[int, str]:\n    if input_result.is_ok():\n        return Ok(input_result.unwrap() * self.factor)\n    return input_result\n</code></pre> Source code in <code>neopipe/task.py</code> <pre><code>class ClassSyncTask(BaseSyncTask[T, E], ABC):\n    \"\"\"\n    Extend this class to create stateful or configurable sync tasks.\n\n    You must override the `execute(self, input_result: Result[T, E])` method.\n\n    Example:\n        class MultiplyTask(ClassSyncTask[int, str]):\n            def __init__(self, factor: int):\n                super().__init__()\n                self.factor = factor\n\n            def execute(self, input_result: Result[int, str]) -&gt; Result[int, str]:\n                if input_result.is_ok():\n                    return Ok(input_result.unwrap() * self.factor)\n                return input_result\n    \"\"\"\n\n    def __init__(self, retries: int = 1):\n        super().__init__(retries)\n</code></pre>"},{"location":"api/task/#neopipe.task.FunctionAsyncTask","title":"<code>FunctionAsyncTask</code>","text":"<p>               Bases: <code>BaseAsyncTask[T, E]</code></p> <p>Wraps an async function that takes a Result[T, E] and returns a Result[U, E].</p> Source code in <code>neopipe/task.py</code> <pre><code>class FunctionAsyncTask(BaseAsyncTask[T, E]):\n    \"\"\"\n    Wraps an async function that takes a Result[T, E] and returns a Result[U, E].\n    \"\"\"\n\n    def __init__(\n        self, func: Callable[[Result[T, E]], Awaitable[Result[U, E]]], retries: int = 1\n    ):\n        super().__init__(retries)\n        self.func = func\n\n    @property\n    def task_name(self) -&gt; str:\n        return self.func.__name__\n\n    async def execute(self, input_result: Result[T, E]) -&gt; Result[U, E]:\n        return await self.func(input_result)\n\n    @classmethod\n    def decorator(cls, retries: int = 1):\n        \"\"\"\n        A decorator for turning an async function into a FunctionAsyncTask.\n\n        Example:\n            @FunctionAsyncTask.decorator(retries=2)\n            async def fetch(result: Result[str, str]) -&gt; Result[str, str]:\n                ...\n\n        Returns:\n            FunctionAsyncTask[T, E]\n        \"\"\"\n\n        def wrapper(func: Callable[[Result[T, E]], Awaitable[Result[U, E]]]) -&gt; Self:\n            task = cls(func, retries)\n\n            @wraps(func)\n            async def wrapped(input_result: Result[T, E]) -&gt; Result[U, E]:\n                return await task(input_result)\n\n            wrapped.task = task\n            return task\n\n        return wrapper\n\n    def __str__(self):\n        return f\"FunctionAsyncTask({self.task_name}, ID={self.task_id})\"\n</code></pre>"},{"location":"api/task/#neopipe.task.FunctionAsyncTask.decorator","title":"<code>decorator(retries=1)</code>  <code>classmethod</code>","text":"<p>A decorator for turning an async function into a FunctionAsyncTask.</p> Example <p>@FunctionAsyncTask.decorator(retries=2) async def fetch(result: Result[str, str]) -&gt; Result[str, str]:     ...</p> <p>Returns:</p> Type Description <p>FunctionAsyncTask[T, E]</p> Source code in <code>neopipe/task.py</code> <pre><code>@classmethod\ndef decorator(cls, retries: int = 1):\n    \"\"\"\n    A decorator for turning an async function into a FunctionAsyncTask.\n\n    Example:\n        @FunctionAsyncTask.decorator(retries=2)\n        async def fetch(result: Result[str, str]) -&gt; Result[str, str]:\n            ...\n\n    Returns:\n        FunctionAsyncTask[T, E]\n    \"\"\"\n\n    def wrapper(func: Callable[[Result[T, E]], Awaitable[Result[U, E]]]) -&gt; Self:\n        task = cls(func, retries)\n\n        @wraps(func)\n        async def wrapped(input_result: Result[T, E]) -&gt; Result[U, E]:\n            return await task(input_result)\n\n        wrapped.task = task\n        return task\n\n    return wrapper\n</code></pre>"},{"location":"api/task/#neopipe.task.FunctionSyncTask","title":"<code>FunctionSyncTask</code>","text":"<p>               Bases: <code>BaseSyncTask[T, E]</code></p> <p>Wraps a function that takes a Result[T, E] and returns a Result[U, E].</p> <p>Can be used as a decorator with automatic retry and logging support.</p> Source code in <code>neopipe/task.py</code> <pre><code>class FunctionSyncTask(BaseSyncTask[T, E]):\n    \"\"\"\n    Wraps a function that takes a Result[T, E] and returns a Result[U, E].\n\n    Can be used as a decorator with automatic retry and logging support.\n    \"\"\"\n\n    def __init__(self, func: Callable[[Result[T, E]], Result[U, E]], retries: int = 1):\n        super().__init__(retries)\n        self.func = func\n\n    @property\n    def task_name(self) -&gt; str:\n        return self.func.__name__\n\n    def execute(self, input_result: Result[T, E]) -&gt; Result[U, E]:\n        return self.func(input_result)\n\n    @classmethod\n    def decorator(cls, retries: int = 1):\n        \"\"\"\n        A decorator for converting a function into a retryable FunctionSyncTask.\n\n        Example:\n            @FunctionSyncTask.decorator(retries=2)\n            def process(result: Result[int, str]) -&gt; Result[int, str]:\n                ...\n\n        Args:\n            retries (int): Number of retry attempts.\n\n        Returns:\n            Callable: A decorator that wraps the function in a FunctionSyncTask.\n        \"\"\"\n\n        def wrapper(func: Callable[[Result[T, E]], Result[U, E]]) -&gt; Self:\n            task = cls(func, retries)\n\n            @wraps(func)\n            def wrapped(input_result: Result[T, E]) -&gt; Result[U, E]:\n                return task(input_result)\n\n            wrapped.task = task  # Optional: attach task instance\n            return task\n\n        return wrapper\n\n    def __str__(self):\n        return f\"FunctionSyncTask({self.task_name}, ID={self.task_id})\"\n</code></pre>"},{"location":"api/task/#neopipe.task.FunctionSyncTask.decorator","title":"<code>decorator(retries=1)</code>  <code>classmethod</code>","text":"<p>A decorator for converting a function into a retryable FunctionSyncTask.</p> Example <p>@FunctionSyncTask.decorator(retries=2) def process(result: Result[int, str]) -&gt; Result[int, str]:     ...</p> <p>Parameters:</p> Name Type Description Default <code>retries</code> <code>int</code> <p>Number of retry attempts.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>Callable</code> <p>A decorator that wraps the function in a FunctionSyncTask.</p> Source code in <code>neopipe/task.py</code> <pre><code>@classmethod\ndef decorator(cls, retries: int = 1):\n    \"\"\"\n    A decorator for converting a function into a retryable FunctionSyncTask.\n\n    Example:\n        @FunctionSyncTask.decorator(retries=2)\n        def process(result: Result[int, str]) -&gt; Result[int, str]:\n            ...\n\n    Args:\n        retries (int): Number of retry attempts.\n\n    Returns:\n        Callable: A decorator that wraps the function in a FunctionSyncTask.\n    \"\"\"\n\n    def wrapper(func: Callable[[Result[T, E]], Result[U, E]]) -&gt; Self:\n        task = cls(func, retries)\n\n        @wraps(func)\n        def wrapped(input_result: Result[T, E]) -&gt; Result[U, E]:\n            return task(input_result)\n\n        wrapped.task = task  # Optional: attach task instance\n        return task\n\n    return wrapper\n</code></pre>"},{"location":"examples/basic_use_async_pipeline_module/","title":"Async Pipeline \u2014 Basic Usage","text":"<p>The AsyncPipeline lets you run independent <code>BaseAsyncTask</code> instances concurrently\u20141:1 matching each task with its input <code>Result</code>. You can also capture a full execution trace by enabling <code>debug</code> mode.</p>"},{"location":"examples/basic_use_async_pipeline_module/#installation","title":"Installation","text":"<pre><code>pip install neopipe\n</code></pre>"},{"location":"examples/basic_use_async_pipeline_module/#imports","title":"Imports","text":"<pre><code>import asyncio\nfrom neopipe.result import Result, Ok, Err\nfrom neopipe.async_task import FunctionAsyncTask, ClassAsyncTask\nfrom neopipe.async_pipeline import AsyncPipeline\n</code></pre>"},{"location":"examples/basic_use_async_pipeline_module/#1-define-your-async-tasks","title":"1. Define Your Async Tasks","text":""},{"location":"examples/basic_use_async_pipeline_module/#11-functionbased-tasks","title":"1.1 Function\u2011based Tasks","text":"<pre><code>@FunctionAsyncTask.decorator(retries=2)\nasync def fetch_user(res: Result[int, str]) -&gt; Result[dict, str]:\n    # Simulate an async I/O call\n    if res.is_ok():\n        await asyncio.sleep(0.1)\n        user_id = res.unwrap()\n        return Ok({\"id\": user_id, \"name\": f\"User{user_id}\"})\n    return res\n</code></pre> <pre><code>@FunctionAsyncTask.decorator()\nasync def validate_user(res: Result[dict, str]) -&gt; Result[dict, str]:\n    if res.is_ok():\n        user = res.unwrap()\n        if not user[\"id\"] or not user[\"name\"]:\n            return Err(\"Invalid user data\")\n        return Ok(user)\n    return res\n</code></pre>"},{"location":"examples/basic_use_async_pipeline_module/#12-classbased-tasks","title":"1.2 Class\u2011based Tasks","text":"<pre><code>class EnrichUserTask(ClassAsyncTask[dict, str]):\n    async def execute(self, res: Result[dict, str]) -&gt; Result[dict, str]:\n        if res.is_ok():\n            user = res.unwrap()\n            # add some computed field\n            user[\"active\"] = (user[\"id\"] % 2 == 0)\n            return Ok(user)\n        return res\n</code></pre>"},{"location":"examples/basic_use_async_pipeline_module/#2-build-the-pipeline","title":"2. Build the Pipeline","text":"<pre><code>pipeline = AsyncPipeline.from_tasks([\n    fetch_user,\n    validate_user,\n    EnrichUserTask()\n], name=\"UserPipeline\")\n</code></pre>"},{"location":"examples/basic_use_async_pipeline_module/#3-run-the-pipeline","title":"3. Run the Pipeline","text":""},{"location":"examples/basic_use_async_pipeline_module/#31-simple-concurrent-run","title":"3.1 Simple Concurrent Run","text":"<pre><code>async def main():\n    inputs = [Ok(1), Ok(2), Ok(3)]  # three independent runs\n    result = await pipeline.run(inputs)\n\n    if result.is_ok():\n        users = result.unwrap()\n        print(\"Enriched users:\", users)\n    else:\n        print(\"Pipeline failed:\", result.err())\n\nasyncio.run(main())\n</code></pre> <p>Expected Output:</p> <pre><code>Enriched users: [\n  {\"id\":1,\"name\":\"User1\",\"active\":False},\n  {\"id\":2,\"name\":\"User2\",\"active\":True},\n  {\"id\":3,\"name\":\"User3\",\"active\":False}\n]\n</code></pre>"},{"location":"examples/basic_use_async_pipeline_module/#32-debug-mode-trace","title":"3.2 Debug Mode (Trace)","text":"<pre><code>async def debug_main():\n    inputs = [Ok(10), Ok(20)]\n    debug_result = await pipeline.run(inputs, debug=True)\n\n    if debug_result.is_ok():\n        outputs, trace = debug_result.unwrap()\n        print(\"Final outputs:\", outputs)\n        print(\"Trace details:\")\n        for task_name, task_res in trace:\n            print(f\" - {task_name}: {task_res}\")\n    else:\n        print(\"Pipeline error:\", debug_result.err())\n\nasyncio.run(debug_main())\n</code></pre>"},{"location":"examples/basic_use_async_pipeline_module/#4-async-pipeline-parallel-execution","title":"4. Async Pipeline Parallel Execution","text":"<p>You can run multiple <code>AsyncPipeline</code> instances concurrently with <code>run_parallel()</code>. Each pipeline executes its sequence of tasks (via <code>run_sequence</code>) with its own input, and you get back a list of <code>PipelineResult</code> objects\u2014and, in debug mode, a full <code>PipelineTrace</code>.</p>"},{"location":"examples/basic_use_async_pipeline_module/#41-define-your-pipelines","title":"4.1. Define your pipelines","text":"<pre><code>import asyncio\nfrom neopipe.result import Result, Ok, Err\nfrom neopipe.async_task import FunctionAsyncTask, ClassAsyncTask\nfrom neopipe.async_pipeline import AsyncPipeline\n\n# \u2014 Sequential pipeline: load \u2192 filter \u2192 extract names\n@FunctionAsyncTask.decorator()\nasync def load_users(res: Result[None, str]) -&gt; Result[list[dict], str]:\n    return Ok([\n        {\"id\": 1, \"name\": \"Alice\", \"active\": True},\n        {\"id\": 2, \"name\": \"Bob\",   \"active\": False},\n        {\"id\": 3, \"name\": \"Carol\", \"active\": True},\n    ])\n\n@FunctionAsyncTask.decorator()\nasync def filter_active(res: Result[list[dict], str]) -&gt; Result[list[dict], str]:\n    if res.is_err():\n        return res\n    return Ok([u for u in res.unwrap() if u[\"active\"]])\n\nclass ExtractNamesTask(ClassAsyncTask[list[dict], str]):\n    async def execute(self, res: Result[list[dict], str]) -&gt; Result[list[str], str]:\n        if res.is_err():\n            return res\n        return Ok([u[\"name\"] for u in res.unwrap()])\n\nseq_pipeline = AsyncPipeline.from_tasks(\n    [load_users, filter_active, ExtractNamesTask()],\n    name=\"UserSeq\"\n)\n\n# \u2014 Independent pipelines: fetch and validate\n@FunctionAsyncTask.decorator()\nasync def fetch_user(res: Result[int, str]) -&gt; Result[dict, str]:\n    if res.is_ok():\n        await asyncio.sleep(0.05)\n        uid = res.unwrap()\n        return Ok({\"id\": uid, \"name\": f\"User{uid}\"})\n    return res\n\n@FunctionAsyncTask.decorator()\nasync def validate_user(res: Result[dict, str]) -&gt; Result[dict, str]:\n    if res.is_ok():\n        user = res.unwrap()\n        if not user.get(\"id\") or not user.get(\"name\"):\n            return Err(\"Invalid\")\n        return Ok(user)\n    return res\n\nfetch_pipeline    = AsyncPipeline.from_tasks([fetch_user],    name=\"FetchUser\")\nvalidate_pipeline = AsyncPipeline.from_tasks([validate_user], name=\"ValidateUser\")\n</code></pre>"},{"location":"examples/basic_use_async_pipeline_module/#42-run-the-pipelines-in-parallel","title":"4.2. Run the pipelines in parallel","text":"<pre><code>async def main():\n    inputs = [\n        Ok(None),                  # seq_pipeline: needs None\n        Ok(42),                    # fetch_pipeline: user ID\n        Ok({\"id\": 99, \"name\": \"X\"})# validate_pipeline: user dict\n    ]\n\n    # debug=False \u21d2 Ok[List[PipelineResult]]\n    res = await AsyncPipeline.run_parallel(\n        [seq_pipeline, fetch_pipeline, validate_pipeline],\n        inputs\n    )\n\n    if res.is_ok():\n        for pr in res.unwrap():\n            print(f\"{pr.name} \u2192 {pr.result}\")\n    else:\n        print(\"Error:\", res.err())\n\nasyncio.run(main())\n</code></pre> <p>Expected Output:</p> <pre><code>UserSeq      \u2192 ['Alice', 'Carol']\nFetchUser    \u2192 {'id':42, 'name':'User42'}\nValidateUser \u2192 {'id':99, 'name':'X'}\n</code></pre>"},{"location":"examples/basic_use_async_pipeline_module/#43-run-the-pipelines-in-parallel-debug-mode","title":"4.3. Run the pipelines in parallel (debug mode)","text":"<pre><code>async def debug_main():\n    inputs = [Ok(None), Ok(7), Ok({\"id\":7,\"name\":\"User7\"})]\n\n    # debug=True \u21d2 Ok((List[PipelineResult], PipelineTrace))\n    res = await AsyncPipeline.run_parallel(\n        [seq_pipeline, fetch_pipeline, validate_pipeline],\n        inputs,\n        debug=True\n    )\n\n    if res.is_ok():\n        results, trace = res.unwrap()\n\n        # Print final results\n        for pr in results:\n            print(f\"{pr.name} \u2192 {pr.result}\")\n\n        # Print per-pipeline, per-task trace\n        for single in trace.pipelines:\n            print(f\"\\nTrace for {single.name}:\")\n            for task_name, task_res in single.tasks:\n                print(f\"  {task_name} \u2192 {task_res}\")\n    else:\n        print(\"Error:\", res.err())\n\nasyncio.run(debug_main())\n</code></pre> <p>Expected Output:</p> <pre><code>UserSeq      \u2192 ['Alice', 'Carol']\nFetchUser    \u2192 {'id':7, 'name':'User7'}\nValidateUser \u2192 {'id':7, 'name':'User7'}\n\nTrace for UserSeq:\n  load_users       \u2192 Ok([...])\n  filter_active    \u2192 Ok([...])\n  ExtractNamesTask \u2192 Ok(['Alice','Carol'])\n\nTrace for FetchUser:\n  fetch_user       \u2192 Ok({'id':7,'name':'User7'})\n\nTrace for ValidateUser:\n  validate_user    \u2192 Ok({'id':7,'name':'User7'})\n</code></pre>"},{"location":"examples/basic_use_async_pipeline_module/#5-notes","title":"5. Notes","text":"<ul> <li>1:1 matching: The <code>inputs</code> list must be the same length as your <code>tasks</code> list.  </li> <li>Short\u2011circuit: The first <code>Err</code> stops the entire pipeline (unless you inspect partial trace).  </li> <li>Retries: Any task annotated with <code>retries &gt; 1</code> will automatically retry on exceptions.  </li> <li>Trace: In <code>debug</code> mode you get a list of <code>(task_name, Result)</code> in the order tasks were run.</li> </ul>"},{"location":"examples/basic_use_pipeline_module/","title":"Basic Usage: Sync Pipeline","text":"<p>The Sync Pipeline ties together multiple <code>BaseSyncTask</code> instances\u2014both function\u2011based and class\u2011based\u2014into a single, sequential workflow. Each task consumes a <code>Result[T, E]</code> and returns a new <code>Result[U, E]</code>. The pipeline stops on the first failure and can optionally emit a full trace for debugging.</p>"},{"location":"examples/basic_use_pipeline_module/#installation","title":"Installation","text":"<pre><code>pip install neopipe\n</code></pre>"},{"location":"examples/basic_use_pipeline_module/#imports","title":"Imports","text":"<pre><code>from neopipe.result import Result, Ok, Err\nfrom neopipe.task import FunctionSyncTask, ClassSyncTask\nfrom neopipe.sync_pipeline import SyncPipeline\n</code></pre>"},{"location":"examples/basic_use_pipeline_module/#1-define-your-tasks","title":"1. Define Your Tasks","text":""},{"location":"examples/basic_use_pipeline_module/#11-functionbased-tasks","title":"1.1 Function\u2011based Tasks","text":"<pre><code>@FunctionSyncTask.decorator(retries=2)\ndef load_users(res: Result[None, str]) -&gt; Result[list[dict], str]:\n    # Simulate loading from a database\n    return Ok([\n        {\"id\": 1, \"name\": \"Alice\", \"active\": True},\n        {\"id\": 2, \"name\": \"Bob\",   \"active\": False},\n        {\"id\": 3, \"name\": \"Carol\", \"active\": True},\n    ])\n</code></pre> <pre><code>@FunctionSyncTask.decorator()\ndef filter_active(res: Result[list[dict], str]) -&gt; Result[list[dict], str]:\n    if res.is_err():\n        return res\n    active = [u for u in res.unwrap() if u[\"active\"]]\n    return Ok(active)\n</code></pre>"},{"location":"examples/basic_use_pipeline_module/#12-classbased-tasks","title":"1.2 Class\u2011based Tasks","text":"<pre><code>class ExtractNamesTask(ClassSyncTask[list[dict], str]):\n    def execute(self, res: Result[list[dict], str]) -&gt; Result[list[str], str]:\n        if res.is_err():\n            return res\n        names = [u[\"name\"] for u in res.unwrap()]\n        return Ok(names)\n</code></pre> <pre><code>class JoinNamesTask(ClassSyncTask[list[str], str]):\n    def execute(self, res: Result[list[str], str]) -&gt; Result[str, str]:\n        if res.is_err():\n            return res\n        return Ok(\", \".join(res.unwrap()))\n</code></pre>"},{"location":"examples/basic_use_pipeline_module/#2-build-the-pipeline","title":"2. Build the Pipeline","text":"<pre><code>pipeline = SyncPipeline.from_tasks([\n    load_users,\n    filter_active,\n    ExtractNamesTask(),\n    JoinNamesTask()\n], name=\"UserNamePipeline\")\n</code></pre>"},{"location":"examples/basic_use_pipeline_module/#3-run-the-pipeline","title":"3. Run the Pipeline","text":""},{"location":"examples/basic_use_pipeline_module/#31-simple-run","title":"3.1 Simple Run","text":"<pre><code>result = pipeline.run(Ok(None))\n\nif result.is_ok():\n    print(\"Final output:\", result.unwrap())\nelse:\n    print(\"Pipeline failed:\", result.err())\n</code></pre> <p>Expected Output:</p> <pre><code>Final output: Alice, Carol\n</code></pre>"},{"location":"examples/basic_use_pipeline_module/#32-debug-mode-trace","title":"3.2 Debug Mode (Trace)","text":"<pre><code>debug_result = pipeline.run(Ok(None), debug=True)\n\nif debug_result.is_ok():\n    final, trace = debug_result.unwrap()\n    print(\"Final:\", final)\n    print(\"Trace:\")\n    for task_name, step_res in trace:\n        print(f\"  - {task_name}: {step_res}\")\nelse:\n    print(\"Pipeline failed:\", debug_result.err())\n</code></pre> <p>Sample Trace:</p> <pre><code>Final: Alice, Carol\nTrace:\n  - load_users: Ok([{'id':1,...}, ...])\n  - filter_active: Ok([{'id':1,...}, {'id':3,...}])\n  - ExtractNamesTask: Ok(['Alice','Carol'])\n  - JoinNamesTask: Ok('Alice, Carol')\n</code></pre>"},{"location":"examples/basic_use_pipeline_module/#4-chaining-pipelines-in-parallel","title":"4. Chaining Pipelines in Parallel","text":"<p>You can execute multiple <code>SyncPipeline</code> instances concurrently with <code>run_parallel</code>. Each pipeline runs in its own thread and returns a list of <code>PipelineResult</code> objects (and, in debug mode, a <code>PipelineTrace</code> with per\u2011task details).</p>"},{"location":"examples/basic_use_pipeline_module/#41-define-your-pipelines","title":"4.1 Define your pipelines","text":"<pre><code>from neopipe.result import Result, Ok\nfrom neopipe.task import FunctionSyncTask, ClassSyncTask\nfrom neopipe.sync_pipeline import SyncPipeline\n\n@FunctionSyncTask.decorator()\ndef compute_length(res: Result[str, str]) -&gt; Result[int, str]:\n    # returns the length of the string\n    return Ok(len(res.unwrap())) if res.is_ok() else res\n\nclass MultiplyTask(ClassSyncTask[int, str]):\n    def __init__(self, factor: int):\n        super().__init__()\n        self.factor = factor\n\n    def execute(self, res: Result[int, str]) -&gt; Result[int, str]:\n        # multiplies the integer by the given factor\n        return Ok(res.unwrap() * self.factor) if res.is_ok() else res\n\n# Pipeline A: compute length \u2192 multiply by 2\npA = SyncPipeline.from_tasks(\n    [compute_length, MultiplyTask(2)],\n    name=\"LengthX2\"\n)\n\n# Pipeline B: compute length \u2192 multiply by 3\npB = SyncPipeline.from_tasks(\n    [compute_length, MultiplyTask(3)],\n    name=\"LengthX3\"\n)\n</code></pre>"},{"location":"examples/basic_use_pipeline_module/#42-run-in-parallel-nondebug","title":"4.2 Run in parallel (non\u2011debug)","text":"<p>You can run the pipelines in parallel by passing a list of inputs, one for each pipeline:</p> <pre><code>inputs = [Ok(\"hello\"), Ok(\"world!\")]  # one input per pipeline\n\nresult = SyncPipeline.run_parallel([pA, pB], inputs)\n\nif result.is_ok():\n    pipeline_results = result.unwrap()\n    # pipeline_results is a List[PipelineResult]:\n    # [\n    #   PipelineResult(name=\"LengthX2\", result=10),\n    #   PipelineResult(name=\"LengthX3\", result=18)\n    # ]\n    for pr in pipeline_results:\n        print(f\"{pr.name} \u2192 {pr.result}\")\nelse:\n    print(\"Error:\", result.err())\n</code></pre>"},{"location":"examples/basic_use_pipeline_module/#43-run-in-parallel-debug-mode","title":"4.3 Run in parallel (debug mode)","text":"<p>Capture a full per\u2011task trace alongside the final results:</p> <pre><code>res_debug = SyncPipeline.run_parallel([pA, pB], inputs, debug=True)\n\nif res_debug.is_ok():\n    pipeline_results, trace = res_debug.unwrap()\n\n    # pipeline_results same as above\n    # trace is a PipelineTrace(pipelines=[SinglePipelineTrace(...), ...])\n\n    # Print results\n    for pr in pipeline_results:\n        print(f\"{pr.name} final \u2192 {pr.result}\")\n\n    # Inspect per\u2011task trace\n    for single in trace.pipelines:\n        print(f\"\\nTrace for {single.name}:\")\n        for task_name, task_res in single.tasks:\n            print(f\"  {task_name} \u2192 {task_res}\")\nelse:\n    print(\"Error:\", res_debug.err())\n</code></pre>"},{"location":"examples/basic_use_result_module/","title":"\ud83e\udde9 Using the <code>Result</code> Class","text":"<p>The <code>Result</code> class is a core utility in this library for representing success (<code>Ok</code>) or failure (<code>Err</code>) outcomes, inspired by Rust.</p> <p>It eliminates the need for try/except blocks by returning an object that contains either a valid value or an error.</p>"},{"location":"examples/basic_use_result_module/#why-use-result","title":"\u2705 Why use <code>Result</code>?","text":"<ul> <li>Clear separation of success and error flows</li> <li>Functional style: <code>map</code>, <code>and_then</code>, <code>unwrap</code>, etc.</li> <li>Built-in support for retries and task composition</li> <li>Consistent return type for sync and async code</li> </ul>"},{"location":"examples/basic_use_result_module/#importing-result","title":"\ud83d\udce6 Importing <code>Result</code>","text":"<pre><code>from result import Result, Ok, Err\n</code></pre>"},{"location":"examples/basic_use_result_module/#creating-a-result","title":"Creating a Result","text":"<pre><code>success = Ok(42)\nfailure = Err(\"Something went wrong\")\n\nprint(success)  # Ok(42)\nprint(failure)  # Err('Something went wrong')\n\n# Checking and Accessing Values\nif success.is_ok():\n    print(\"Value:\", success.unwrap())\n\nif failure.is_err():\n    print(\"Error:\", failure.err())\n</code></pre>"},{"location":"examples/basic_use_result_module/#transforming-with-map-and-map_err","title":"\ud83d\udd01 Transforming with <code>map</code> and <code>map_err</code>","text":"<pre><code>result = Ok(5).map(lambda x: x * 2)  # Ok(10)\n\nerror_result = Err(\"bad input\").map_err(lambda e: f\"Error: {e}\")\n# Err(\"Error: bad input\")\n</code></pre>"},{"location":"examples/basic_use_result_module/#chaining-with-and_then","title":"\ud83d\udd17 Chaining with <code>and_then</code>","text":"<pre><code>def safe_divide(x: int, y: int) -&gt; Result[float, str]:\n    if y == 0:\n        return Err(\"Division by zero\")\n    return Ok(x / y)\n\nresult = Ok((10, 2)).and_then(lambda pair: safe_divide(*pair))\n# Ok(5.0)\n</code></pre>"},{"location":"examples/basic_use_result_module/#unwrapping-and-defaults","title":"\ud83e\uddef Unwrapping and Defaults","text":"<pre><code>print(Ok(\"hello\").unwrap())  # \"hello\"\nprint(Err(\"boom\").unwrap_or(\"default\"))  # \"default\"\nprint(Err(\"fail\").unwrap_or_else(lambda e: f\"Handled: {e}\"))  # \"Handled: fail\"\n</code></pre>"},{"location":"examples/basic_use_result_module/#pattern-matching","title":"\u26a1 Pattern Matching","text":"<pre><code>result = Ok(100)\n\nmessage = result.match(\n    ok_fn=lambda x: f\"Success: {x}\",\n    err_fn=lambda e: f\"Failure: {e}\"\n)\n\nprint(message)  # Success: 100\n</code></pre>"},{"location":"examples/basic_use_result_module/#async-support","title":"\ud83c\udf10 Async Support","text":"<p>The Result object includes async versions of map, map_err, and and_then.</p> <pre><code>async def double_async(x: int) -&gt; int:\n    return x * 2\n\nresult = await Ok(5).map_async(double_async)\n# Ok(10)\n\nasync def validate(x: int) -&gt; Result[str, str]:\n    return Ok(f\"value: {x}\") if x &gt; 0 else Err(\"Too small\")\n\nresult = await Ok(3).and_then_async(validate)\n# Ok(\"value: 3\")\n</code></pre>"},{"location":"examples/basic_use_result_module/#real-world-usage","title":"\ud83e\uddea Real World Usage","text":"<pre><code>def get_user(user_id: int) -&gt; Result[dict, str]:\n    if user_id == 42:\n        return Ok({\"id\": 42, \"name\": \"Douglas\"})\n    return Err(\"User not found\")\n</code></pre>"},{"location":"examples/basic_use_task_module/","title":"Task Module","text":"<p>The Sync Task system provides a uniform, retryable wrapper around functions and classes that operate on <code>Result[T, E]</code>. Instead of raising exceptions, every task consumes a <code>Result</code> and returns a new <code>Result</code>, enabling safe, composable pipelines.</p>"},{"location":"examples/basic_use_task_module/#overview","title":"Overview","text":"<ul> <li>BaseSyncTask   Abstract base that handles:</li> <li>Retry with exponential backoff  </li> <li>Task identification (<code>task_id</code>, <code>task_name</code>)  </li> <li>Logging on attempts, success, and failure  </li> </ul>"},{"location":"examples/basic_use_task_module/#functionsynctask","title":"FunctionSyncTask","text":"<p>Decorator wrapper for free functions:   ```python   @FunctionSyncTask.decorator(retries=2)   def my_task(res: Result[int, str]) -&gt; Result[int, str]:       if res.is_ok():           return Ok(res.unwrap() + 1)       return res</p> <pre><code>## ClassSyncTask\nSubclass for stateful or multi\u2011step logic:\n\n```python\nclass MultiplyTask(ClassSyncTask[int, str]):\n    def __init__(self, multiplier: int):\n        super().__init__(retries=3)\n        self.multiplier = multiplier\n\n    def execute(self, res: Result[int, str]) -&gt; Result[int, str]:\n        if res.is_ok():\n            return Ok(res.unwrap() * self.multiplier)\n        return res\n</code></pre>"},{"location":"examples/basic_use_task_module/#basesynctask","title":"BaseSyncTask","text":"<pre><code>from neopipe.task import BaseSyncTask\nfrom neopipe.result import Result, Ok, Err\n\nclass EchoTask(BaseSyncTask[str, str]):\n    def execute(self, res: Result[str, str]) -&gt; Result[str, str]:\n        return Ok(res.unwrap()) if res.is_ok() else res\n\ntask = EchoTask()\nprint(task(Ok(\"hello\")))  # Ok(\"hello\")\n</code></pre>"},{"location":"examples/basic_use_task_module/#functionsynctask_1","title":"FunctionSyncTask","text":"<pre><code>from neopipe.task import FunctionSyncTask\nfrom neopipe.result import Result, Ok, Err\n\n@FunctionSyncTask.decorator(retries=2)\ndef add_ten(res: Result[int, str]) -&gt; Result[int, str]:\n    if res.is_ok():\n        return Ok(res.unwrap() + 10)\n    return res\n\nprint(add_ten(Ok(5)))  # Ok(15)\n</code></pre>"},{"location":"examples/basic_use_task_module/#classsynctask","title":"ClassSyncTask","text":"<pre><code>from neopipe.task import ClassSyncTask\nfrom neopipe.result import Result, Ok\n\nclass SquareTask(ClassSyncTask[int, str]):\n    def execute(self, res: Result[int, str]) -&gt; Result[int, str]:\n        if res.is_ok():\n            return Ok(res.unwrap() ** 2)\n        return res\n\ntask = SquareTask()\nprint(task(Ok(3)))  # Ok(9)\n</code></pre> <p>Read the Pipeline Basics to see how to chain Sync Tasks.</p>"},{"location":"examples/basic_use_task_module/#functionasynctask","title":"FunctionAsyncTask","text":"<pre><code>from neopipe.async_task import FunctionAsyncTask\nfrom neopipe.result import Result, Ok, Err\n\n@FunctionAsyncTask.decorator(retries=2)\nasync def shout(res: Result[str, str]) -&gt; Result[str, str]:\n    if res.is_ok():\n        return Ok(res.unwrap().upper())\n    return res\n\nprint(await shout(Ok(\"hello\")))  # Ok(\"HELLO\")\n</code></pre>"},{"location":"examples/basic_use_task_module/#classasynctask","title":"ClassAsyncTask","text":"<pre><code>from neopipe.async_task import ClassAsyncTask\nfrom neopipe.result import Result, Ok\n\nclass ReverseTask(ClassAsyncTask[str, str]):\n    async def execute(self, res: Result[str, str]) -&gt; Result[str, str]:\n        if res.is_ok():\n            return Ok(res.unwrap()[::-1])\n        return res\n\ntask = ReverseTask()\nprint(await task(Ok(\"abc\")))  # Ok(\"cba\")\n</code></pre>"}]}